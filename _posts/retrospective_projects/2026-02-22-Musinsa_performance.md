---
layout: post
title: "수강신청 시스템 성능 분석 — 락 vs 대기열 vs Celery Beat 배치"
date: 2026-02-22
categories: [retrospective]
description: "동기/비동기 Redis 구조적 한계, 대기열 시스템 도입, Celery Beat 배치 처리 분석"
---

![무신사 이미지](/public/images/musinsa.png)

## 개요

> 과제가 종료된 후, 병목 지점을 검토했다.
>
> 사용자 → nginx → WAS → Redis | DB 흐름에서 병목이 발생하는 지점은 보통 두 곳이다.
>
> 1. `nginx → WAS`: Worker가 바빠서 발생
> 2. `WAS → Redis | DB`: I/O 처리 지연
>
> 1개의 Worker가 최대 몇 건의 요청을 처리할 수 있을까? AS-IS 상태에서 실측한 결과 초당 약 280건이었다. 대기열 시스템을 도입하면 더 많은 양을 처리할 수 있겠다는 생각에서 분석을 시작했고, 동기 Redis BLPOP 락 → asyncio Worker 대기열 → Celery Beat 배치 처리로 단계적으로 고도화했다.

---

## 동기 / 비동기 Redis의 구조적 한계

**동기 Redis + BLPOP**

> 워커 N개 = 최대 커넥션 N개. BLPOP이 스레드를 블로킹하므로 커넥션이 터질 구조 자체가 없다.
>
> 단, BLPOP 대기 중에는 스레드 전체가 멈추므로 FastAPI의 async 장점을 완전히 포기하게 된다. 사실상 동기 서버로 동작한다.

**비동기 Redis + BLPOP**

> 코루틴은 수천 개 동시 실행이 가능하다. 각 코루틴이 BLPOP 대기 중 커넥션을 점유하므로, 18,000개 요청이 동시에 대기에 들어가면 18,000개의 커넥션이 필요해진다.
>
> 커넥션 풀 기본 크기(10~50)를 즉시 고갈시키고, 풀 크기를 늘리면 이번엔 Redis 서버의 `maxclients`(기본 10,000, 실무 상한 ~20,000)에 걸린다.
>
> FastAPI의 비동기 처리량을 살리려다가 오히려 Redis 커넥션 풀 고갈이라는 더 큰 문제가 생긴다.

> 어느 방향이든 **BLPOP을 잡고 대기하는 구조 자체가 문제**다. 이것이 대기열 시스템을 검토하게 된 출발점이다.

---

## AS-IS: Redis 분산 락

**흐름**

![sync 시퀸스 다이어그램](/public/images/sync.png)

```
사용자 요청 → BLPOP(락 대기) → SET owner → 비즈니스 로직 → Lua 스크립트 해제
```

**문제점**

> - 요청 1건당 Redis 연산 4~6회 (BLPOP, SET, Lua, DEL 등) → 18,000 RPS 기준 약 90,000 ops/sec로 단일 Redis 한계(~100,000 ops/sec)에 근접
> - 락 경쟁이 심해질수록 타임아웃으로 인한 실패율 급등 (워커를 늘려도 Non-2xx 95% 이상)
> - 동기 Redis이므로 BLPOP이 스레드를 블로킹 → FastAPI async 장점 미활용, 처리량이 워커 수에 직접 비례

---

## TO-BE: Celery Beat 배치 처리

> 대기열로 바꾸면 API 서버는 `ZADD` 1번만 하고 즉시 반환한다. 커넥션을 잡고 대기하는 일이 없으므로, 비동기 Redis를 사용해도 풀 고갈 문제가 없고 FastAPI async 장점도 온전히 활용할 수 있다.

```
AS-IS: 요청 → BLPOP 대기(커넥션 점유 최대 30초) → 처리
TO-BE: 요청 → ZADD(즉시 반환, 커넥션 반납)    → 202 응답
```

**최종 구조: Celery Beat 1초 배치 처리**

![celery beat 시퀸스 다이어그램](/public/images/beat.png)

```
사용자 요청 → ZADD(큐 삽입, 1회) → 즉시 202 + ticket_id 반환

[Celery Beat — 1초마다 실행]
  1. ZPOPMIN(취소 큐) → 취소 먼저 처리 (자리 복구)
  2. ZPOPMIN(신청 큐) → 복구된 자리 포함해 메모리 내 FIFO 검증
  3. 트랜잭션 1회: bulk DELETE + bulk INSERT + bulk UPDATE

클라이언트 폴링:
  GET /enrollments/queue/{ticket_id}/status
  ← { status: "pending" } → "처리 중"
  ← { status: "success" } → "신청 완료"
```

> 처음에는 asyncio Worker(50ms 폴링, 1건씩 처리)를 검토했다. 그런데 Worker 자체에도 병목이 생겼다. 1건씩 처리하다 보니 DB에 매번 연결하게 되는데, WAS가 건네주는 job이 폭주하면 DB connection 제한 이슈가 발생한다. 처리 속도가 요청 속도에 비례해야 하는데, asyncio Worker 1개로는 한계가 있었다.
>
> 그래서 Celery Beat 방식으로 전환했다. 오버 엔지니어링처럼 보일 수 있지만, 1초마다 한 번의 트랜잭션으로 전체 큐를 소진하는 구조는 **DB 쓰기 횟수를 극단적으로 줄인다**. 건당 1회 쓰기에서 배치당 1회 쓰기로, 비용 절감 효과가 명확하다.
>
> 순서 보장도 자연스럽게 따라온다:
> - asyncio Worker: 큐에서 1건씩 꺼내 처리 → 취소 요청보다 신청 요청이 먼저 처리될 수 있음
> - Celery Beat: 1초마다 전체 큐를 한 번에 꺼내 **취소 → 신청 순서**로 메모리 내 처리 → 취소로 생긴 자리를 동일 배치 내 신청이 즉시 활용 가능


---

## 부하 테스트 결과

> wrk -t4 -c100 -d30s, Docker standalone (MacBook Air M2, 8코어), celery-beat 정상 실행 + Redis bgsave 수정 후 재측정.
>
> Beat 방식의 수치는 두 가지를 분리해서 봐야 한다. API 레이어(ZADD 수용 속도)와 실제 DB enrollment 처리량은 완전히 다른 개념이다.

**① API 레이어 처리량 (wrk 직접 측정)**

| | 1w + 락 | 4w + 락 | 1w + Beat | 4w + Beat |
|:---:|:---:|:---:|:---:|:---:|
| RPS | 282 | 828 | 2,990 | **7,490** |
| Avg Latency | 359ms | 134ms | 33ms | **14ms** |

**② 실제 DB enrollment 처리량 비교 — PERF_TEST_MODE (정원=9,999, 초기 수강신청 없음)**

> **[락 방식]** wrk 30s 직접 측정 후 DB 카운트 비교.
> **[Beat 방식]** Beat 중지 → 46,899건 큐 적재 → Beat 재시작 후 드레인 완료까지 정밀 측정.

| | 1w + 락 | 4w + 락 | Beat (단일 worker) |
|:---:|:---:|:---:|:---:|
| 총 요청 처리 RPS | 272 | 775 | — |
| **실제 DB 등록/s** | **68.7** | **199.2** | **~3,658** |
| 큐 소화 속도 | — | — | ~47,000 items/s |
| 46,899건 소화 시간 | ~682s | ~235s | **~1초** |

> - Beat는 동일 46,899건을 **~1초**에 소화. 1w 락 기준 동일 처리에 ~682초 필요.
> - 실 등록 처리량: Beat 3,658/s vs 4w 락 199/s → **약 18배 차이**
> - Beat의 진짜 강점은 "락 없이 비동기 수용 → 배치 bulk insert 1회"로 DB 쓰기 횟수를 극단적으로 줄이는 것.

---

## 정합성 검증 (8가지 시나리오)

> 성능 수치만으로는 부족하다. 동시성 버그가 없는지 직접 검증했다.
> `bench/correctness_test.py`를 작성해 3가지 방식 × 4가지 시나리오를 커버했다.

| # | 시나리오 | 검증 기준 |
|---|---|---|
| 1 | 기본 정원 제한 — 분산 락 | `enrolled ≤ max_capacity` |
| 2 | 기본 정원 제한 — Celery Beat 배치 | `enrolled ≤ max_capacity` |
| 3 | 기본 정원 제한 — Celery 단건 | `enrolled ≤ max_capacity` |
| 4 | 수강취소 — Beat 배치 취소 큐 | 전건 취소 성공 |
| 5 | 취소·등록 동시 — Beat 배치 | 취소된 자리 재활용, `enrolled ≤ max_capacity` |
| 6 | 대규모 동시 요청 — Beat 배치 (100건+) | `enrolled ≤ max_capacity` |
| 7 | 학점 초과 동시 신청 — 분산 락 / Beat 배치 | `total_credits ≤ 18` |
| 8 | 시간표 충돌 동시 신청 — 분산 락 / Beat 배치 | 최종 시간표 충돌 없음 |

**시나리오 5 (취소·등록 동시) — Beat 배치 핵심**

> Beat는 동일 배치 내에서 **취소 먼저 → 신청 나중** 순서로 처리한다. 취소로 생긴 자리가 같은 배치 내 신청 요청에 즉시 활용된다.
>
> asyncio Worker에서 Celery Beat으로 전환한 이유는 순서 보장만이 아니다. Worker 자체의 처리 병목 + DB 쓰기 횟수 절감이라는 실용적 판단이 함께 작용했다. 오버 엔지니어링처럼 보일 수 있지만, 배치당 트랜잭션 1회라는 구조가 가져오는 비용 절감은 명확하다.

```
처리 전: 37명 수강 (정원 100)
취소 8건 + 신청 18건 동시 제출
Beat 배치: 취소 8건 처리 → 자리 복구 → 신청 18건 성공
처리 후: 47명 수강 ✅ (정원 초과 없음)
```

## 트레이드오프

| 관점 | AS-IS (락) | TO-BE (Celery Beat 배치) |
|---|---|---|
| 처리량 | 낮음 (락 경쟁 → 타임아웃) | 높음 (직렬화 → 실패 없음) |
| 응답 방식 | 동기 (즉시 성공/실패) | 비동기 (폴링 필요, ~1초 대기) |
| 배치 내 순서 | 해당 없음 | 취소 → 신청 순서 보장 |
| 실패 모드 | 단순 | 복잡 (Celery Beat 장애) |
| 인프라 복잡도 | 낮음 | 높음 (Celery Beat 별도 운영) |
| UX | 즉시 결과 확인 가능 | 수 초간 "처리 중" 화면 노출 |

> 락과 Beat 중 하나가 절대적으로 우월한 것이 아니다. 처리량이 중요하다면 Beat, 구현 단순성과 즉각적인 UX가 중요하다면 락이 맞다. 서비스 특성과 팀의 운영 역량에 맞게 선택하는 것이 핵심이다.

---

## 결론

> 이번 과제를 통해 동시성 제어를 단계적으로 고도화하는 과정을 직접 경험했다.
>
> 처음에는 단순한 Redis Lock으로 시작했다. 이내 polling 방식이 FIFO를 보장하지 않는다는 걸 알게 됐고, BLPOP 기반 FIFO Lock으로 전환했다. 하지만 FIFO Lock을 구현하면서 원자성, Race Condition, 토큰 유실이라는 예상치 못한 문제들을 연달아 만났다. 각 문제를 하나씩 해결하는 과정에서 Redis의 동작 원리를 깊게 이해하게 됐다.
>
> 과제가 끝나고 나서는 동기/비동기 Redis의 구조적 한계를 분석하면서, BLPOP으로 대기하는 구조 자체가 문제라는 결론에 도달했다. 대기열 시스템을 도입했고, asyncio Worker를 먼저 검토했지만 Worker 자체에도 처리 병목이 생겼다. Celery Beat 배치 처리로 전환하면서 Worker 병목을 해소하고, DB 쓰기 횟수도 배치당 1회로 줄였다. 오버 엔지니어링처럼 보일 수 있지만 비용 절감 효과가 명확하고, "취소와 신청이 동시에 들어왔을 때 취소된 자리를 즉시 재활용"이라는 요구사항도 자연스럽게 충족됐다.

**배운 것**

> 설계가 엔지니어의 핵심 덕목이 될 것이라 생각한다.
>
> 병목 지점을 점검하고, 발생 가능한 시나리오를 구상한다. 해당 지점에서 발생할 문제를 미리 발견하고 예방한다.
>
> 이번 과제는 그 사고방식을 실제로 적용해본 경험이었다.
>
> 이 과제는 Claude Code를 활용해 개발했다. 직접 코드를 치는 시간보다 "왜 이렇게 동작하는가"를 이해하고 검증하는 데 더 많은 시간을 썼다. AI와 함께 개발할수록 설계 판단력이 더 중요해진다는 걸 체감했다.

**다음에 해보고 싶은 것**

> 비즈니스 로직이 단순하다 보니 싱글 인스턴스로도 가능해 보이지만, 실제 비즈니스 로직에서는 요청 처리량이 더 줄어들 것이다.
>
> 18,000개의 요청을 정말 다 소화해야 한다면 스케일업을 하거나, N개의 인스턴스로 스케일 아웃이 필요해 보인다.
>
> 일반적인 티켓팅 시스템에서는 Worker를 사용한다고 한다. N개의 API 인스턴스 + N개의 Celery Worker 구성을 구현해보고 싶다. 이 구조에서 Worker 장애 시 큐가 쌓이는 문제와 재처리(idempotency) 보장도 함께 다뤄보고 싶다.
